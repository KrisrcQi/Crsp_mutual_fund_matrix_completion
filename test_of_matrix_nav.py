# -*- coding: utf-8 -*-
"""Test_of_matrix_NAV.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/KrisrcQi/Crsp_mutual_fund_matrix_completion/blob/main/Test_of_matrix_NAV.ipynb
"""

import pandas as pd
import numpy as np


# Reading the data file
# Checking the empty cells in the dataset
df = pd.read_csv('Downsized dataset(10k row).csv')
print(df)
small_date = df['caldt'].min()
print(small_date)
max_date = df['caldt'].max()
print(max_date)

df_1 = df[: 633]
df_1 = df.drop(['caldt'], axis=1)
df_1

!pip install torch-geometric



import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch_geometric.data import Data, DataLoader
from torch_geometric.nn import GCNConv

data = df_1
num_features = 10

# Step 1: Convert matrix to graph representation
adjacency_matrix = torch.tensor(data.values)  # Convert matrix to tensor
edge_index = adjacency_matrix.nonzero().t()  # Get indices of non-zero values as edges
x = torch.randn(adjacency_matrix.size(0), num_features)  # Node features (randomly initialized)

adjacency_matrix

edge_index

x

# Step 2: Split the dataset
# Randomly remove some values to create observed values dataset
observed_matrix = adjacency_matrix.clone()
indices = torch.randperm(adjacency_matrix.numel())[:int(0.8 * adjacency_matrix.numel())]
observed_matrix.reshape(-1)[indices] = float('nan')
# Keep missing values as the evaluation dataset
missing_values = adjacency_matrix.clone()
missing_values.reshape(-1)[indices] = float('nan')

# Step 3: Construct the GNN model
class GNNModel(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super(GNNModel, self).__init__()
        self.conv1 = GCNConv(input_dim, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, hidden_dim)
        self.fc = nn.Linear(hidden_dim, 1)

    def forward(self, x, edge_index):
        x = F.relu(self.conv1(x, edge_index))
        x = F.relu(self.conv2(x, edge_index))
        x = self.fc(x).squeeze()
        return x

input_dim = num_features  # Dimensionality of input features
hidden_dim = 64  # Dimensionality of hidden layers

model = GNNModel(input_dim, hidden_dim)

# Step 4: Train the GNN model
criterion = nn.MSELoss()  # Mean Squared Error loss
optimizer = optim.Adam(model.parameters(), lr=0.01)

data = Data(x=x, edge_index=edge_index)
loader = DataLoader([data], batch_size=64)  # DataLoader for a single graph

num_epochs = 40

# Training loop
for epoch in range(num_epochs):
    model.train()
    for batch in loader:
        optimizer.zero_grad()
        output = model(batch.x, batch.edge_index)
        target = batch.x.t()  # Transpose the target tensor to match output shape
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss}")

# Step 5: Evaluate the GNN model
model.eval()
with torch.no_grad():
    missing_values_prediction = model(x, edge_index)  # Predict missing values


# Convert the predicted missing values back to a matrix
predicted_matrix = adjacency_matrix.clone().double()  # Convert predicted_matrix to Double data type
selected_indices = indices[:missing_values_prediction.size(0)]
predicted_matrix.reshape(-1)[selected_indices] = missing_values_prediction.double()  # Convert missing_values_prediction to Double data type

# Print the predicted matrix
torch.set_printoptions(precision=2)
print(predicted_matrix)

# Convert the tensor to a NumPy array
predicted_array = predicted_matrix.numpy()

# Create a new DataFrame from the array
predicted_df = pd.DataFrame(predicted_array)

# Print the new DataFrame
print(predicted_df)

predicted_df.to_csv('predicted matrix.csv')